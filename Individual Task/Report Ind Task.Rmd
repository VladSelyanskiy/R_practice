---
title: "Отчет о выполнении индивидуального задания"
output:
  word_document: default
---

### Разработка предиктивной модели для определения вероятности заболевания диабетом 

Целью является прогнозировать вероятность наличия диабета и распределение по ней наблюдаемых объектов по двум классам: 0 - отсутствие и 1 - наличие соответсвующего заболевания

Это может быть полезно медицинским работникам при выявлении пациентов, которые могут быть подвержены риску развития диабета, и при разработке индивидуальных планов лечения.

### Описание используемой модели
Для предсказания использована одно из семейств моделей GLM
Существует несколько семейств моделей GLM в зависимости от состава переменной отклика. Для работы выбрана биномиальное семейство. Выбор основан на том, что Биномиальное семейство используется для бинарных переменных отклика (т.е. двух категорий) и предполагает биномиальное распределение. Иными словами, в работе используется логистическая регрессия, которая будет определять зависимую бинарную переменную наличия заболевания от независимых переменных. Независимыми переменными будут служить все остальные переменные в train_data в качестве предикторов. Это может включать различные факторы, такие как возраст, индекс массы тела, уровень глюкозы и т.д.


## Описание набора данных

Набор данных взят с сайта kaggle.  Ссылка для скачивания: <https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset/data>

Набор данных для прогнозирования диабета представляет собой набор медицинских и демографических данных о пациентах, а также их диабетическом статусе (положительном или отрицательном). Эти данные включают такие характеристики, как возраст, пол, индекс массы тела (ИМТ), наличие гипертонии, наличие заболевания сердца, история курения, уровень HbA1c и глюкозы в крови. Этот набор данных используется для построения модели машинного обучения и прогнозирования диабета у пациентов на основе их истории болезни и демографической информации. 

Это может быть полезно медицинским работникам при выявлении пациентов, которые могут быть подвержены риску развития диабета, и при разработке индивидуальных планов лечения.

### Подробный разбор кода

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Разработка модели

# Подключение необходимых пакетов

```{r libraries}
# libraries
library("caret")
library("ggplot2")
library("ROCR")
set.seed(42)
```

## Чтение и предобработка данных
1. Считывание данных из файла
Загрузим данные из файла CSV с именем "diabetes_prediction_dataset.csv" и сохраним их в переменной my_df. 
Также посмотрим структуру данных.

```{r read}
my_df <- read.csv("diabetes_prediction_dataset.csv")
str(my_df)
```

2. Преобразование столбцов в факторы
Некоторые столбцы измерены не в количественных шкалах, их стоит перевести в фактор, что позволит R правильно обрабатывать категориальные переменные.

```{r to_factor}
my_df[, c(1, 3, 4, 5, 9)] <- lapply(my_df[, c(1, 3, 4, 5, 9)], as.factor)
str(my_df)
```

3. Удаление дубликатов и проверка на наличие пропущенных значений.

```{r repeated}
# удалим повторяющиеся записи
my_df <- unique(my_df)
# проверим на пропущенные значения
any(is.na(my_df))
```

Пропущенных значений нет, теперь можно посмотреть краткую сводку о данных и перейти к обработке данных.

```{r summary}
summary(my_df)
```

4. Удаление выбросов методом межквартильного размаха.

Есть подозрения на наличие выбросов в переменной bmi.
Это можно проверить с помощью графика boxplot (ящик с усами)
```{r}
boxplot(my_df$bmi, main = "bmi")
```

Как видно, существует множество значений, выходящих за границу крайних квартелей. Удалим наблюдения с ними для лучшей работы моделей

```{r iqr}
# удаляем выбросы
q_1 <- quantile(my_df$bmi, 0.25)
q_3 <- quantile(my_df$bmi, 0.75)
iqr <- q_3 - q_1
lower_bound <- q_1 - 1.5 * iqr
upper_bound <- q_3 + 1.5 * iqr
my_df <- my_df[my_df$bmi >= lower_bound & my_df$bmi <= upper_bound, ]
```

5. Стандартизация данных.

```{r process}
my_df[, -c(1, 3, 4, 5, 9)] <- sapply(my_df[, -c(1, 3, 4, 5, 9)], scale)
head(my_df)
```

6. Разделение данных на обучающую и тестовую выборки.
В этом шаге данные разделяются на обучающую (70%) и тестовую (30%) выборки. Функция createDataPartition используется для случайного выбора индексов для обучающей выборки, а оставшиеся данные используются для тестовой выборки.

```{r split}
# split data
train_index <- createDataPartition(my_df$diabetes, p = 0.7, list = FALSE)
train_data <- my_df[train_index, ]
test_data <- my_df[-train_index, ]
```

## Обучение модели и предсказание модели.

```{r train}
# train model on split data
model <- glm(diabetes ~ ., data = train_data, family = "binomial")

predictions <- predict(model, newdata = test_data[, c(-9)], type = "response")
```

Выполнив код мы получили вероятности того, относится ли наблюдаемый объект к классу 1 (имеется диабет). Установив пороговое значение, мы сможем определять сам класс. 

## Определение порогового значения
Теперь остро встает вопрос определения порогового значения для отнесения объекта к классу. Для этого в своих воспользуемся визуализацией метрик модели

Для начала отобразим ROC curve, чтобы убедиться в хорошей точности модели и отсутствии перекошенности.

```{r roc}
#####
pred_fit <- prediction(as.numeric(predictions), as.numeric(test_data$diabetes))
perf_fit <- performance(pred_fit, "tpr", "fpr")
plot(perf_fit)
# Add a diagonal reference line
abline(a = 0, b = 1, col = "red", lty = 2)
```

Теперь отобразим две метрики spec and sens. Их пересечение позволит определить оптимальнейшую границу.

```{r threshold}
#####
perf3 <- performance(pred_fit, x.measure = "cutoff", measure = "spec")
perf4 <- performance(pred_fit, x.measure = "cutoff", measure = "sens")

plot(perf3, col = "red", lwd = 2)
plot(add = T, perf4, col = "green", lwd = 2)
# Отобразим линию пересечения на координате 0.07
abline(v = 0.07, lwd = 2)
```

Так мы определили пороговое значение, и теперь можем поменять предсказанные вероятности на определенный класс.

```{r}
threshold <- 0.07
```

# Определим классы и вектор с метками, которые говрят о правильности определения класса.

```{r predict}
predicted_classes <- ifelse(predictions > threshold, 1, 0)

correct <- ifelse(predicted_classes == test_data$diabetes, 1, 0)
```

# Используем различные метрики точности модели.

```{r metrics}
predicted_classes <- factor(predicted_classes)
test_data$diabetes <- factor(test_data$diabetes)

confusion_matrix <- confusionMatrix(predicted_classes, test_data$diabetes)
print(confusion_matrix)
#####

accuracy <- mean(correct)
f1_score <- confusion_matrix$byClass["F1"]
```

Итак, мы получили Confusion matrix (матрицу ошибок) с различными метриками и две основные: accuracy = `r accuracy` and f1 score = `r f1_score`.

# Сохранение модели.
Сохраним модель вместе с пороговым значением в model.RData.

```{r saving}
threshold <- 0.07
save(model, threshold, file = "model.RData")
```
